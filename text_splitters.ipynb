{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d71dfe",
   "metadata": {},
   "source": [
    "## üß† Text Splitters in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a12abe",
   "metadata": {},
   "source": [
    "### ***üî∑ üîç Background***\n",
    "\n",
    "- In LangChain, documents are typically too long for LLMs to process in one go due to token limits.\n",
    "Text splitters are utilities that break down large documents into smaller, manageable chunks that can be effectively processed by LLMs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c999418d",
   "metadata": {},
   "source": [
    "\n",
    "### ***üí° üìå Why Use Text Splitters?***\n",
    "\n",
    "+ Helps overcome token limits of LLMs\n",
    "+ Improves context retention during Q&A or summarization\n",
    "+ Enhances semantic chunking (better understanding)\n",
    "+ Enables parallel processing or chunk-wise embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24177b4",
   "metadata": {},
   "source": [
    "### ***‚öôÔ∏è Common Use Cases***\n",
    "\n",
    "‚úÖ Document QA systems\n",
    "\n",
    "‚úÖ Chat with PDFs or long reports\n",
    "\n",
    "‚úÖ Chunking before embedding generation\n",
    "\n",
    "‚úÖ Summarization pipelines\n",
    "\n",
    "‚úÖ Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1a91d4",
   "metadata": {},
   "source": [
    "### ***üõ†Ô∏è Types of Text Splitters in LangChain***\n",
    "\n",
    "| Splitter Type                           | Description                                                                |\n",
    "| --------------------------------------- | -------------------------------------------------------------------------- |\n",
    "| `CharacterTextSplitter`                 | Splits text using a fixed character count                                  |\n",
    "| `RecursiveCharacterTextSplitter`        | Smart splitter that avoids cutting mid-sentence or word; preferred default |\n",
    "| `TokenTextSplitter`                     | Splits based on token count (token = word pieces understood by LLM)        |\n",
    "| `SentenceTransformersTokenTextSplitter` | Based on sentence transformer token limits (e.g. BERT, RoBERTa)            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a976c90",
   "metadata": {},
   "source": [
    "üß™ ‚úÖ Example: RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed686c2",
   "metadata": {},
   "source": [
    "``` python\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(long_text)\n",
    "print(chunks[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc99e6e",
   "metadata": {},
   "source": [
    "\n",
    "> üîÅ chunk_overlap helps maintain continuity\n",
    "\n",
    "> üìè chunk_size = Max size of each chunk in characters/tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4b2f4e",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è Problem: Large Documents vs. LLM Token Limits\n",
    "\n",
    "- Language models (like GPT-4) have a token limit (e.g., 4K, 8K, or 32K tokens)\n",
    "- Real-world documents (PDFs, articles, reports) often exceed this limit\n",
    "\n",
    "- You‚Äôll hit token limit errors\n",
    "- You risk cutting off important context\n",
    "- You reduce accuracy and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc8ee88",
   "metadata": {},
   "source": [
    "‚úÖ Solution: Use Text Splitters\n",
    "Text splitters help by breaking large documents into smaller, logical chunks.\n",
    "\n",
    "| üîπ Reason              | üîç Explanation                                            |\n",
    "| ---------------------- | --------------------------------------------------------- |\n",
    "| Token limits           | LLMs can‚Äôt process long documents at once                 |\n",
    "| Semantic understanding | Small chunks retain meaning better                        |\n",
    "| Structured processing  | Allows batch processing, embedding, QA, and summarization |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c228d4",
   "metadata": {},
   "source": [
    ">> ### ***üìè 1. Length-Based Splitters:***\n",
    "\n",
    "Split purely by character or token length, regardless of sentence or paragraph structure.\n",
    "\n",
    "+ Fast and deterministic\n",
    "- May cut off sentences or meaning mid-way\n",
    "\n",
    "\n",
    "Examples:\n",
    "\n",
    "CharacterTextSplitter\n",
    "\n",
    "TokenTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6c431",
   "metadata": {},
   "source": [
    ">> ### ***üìÑ 2. Text Structure-Based Splitters***\n",
    "\n",
    "Use textual separators (like \\n\\n, ., or whitespace) to split while maintaining logical boundaries such as sentences or paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a87096",
   "metadata": {},
   "source": [
    "+ More natural splits than fixed-length\n",
    "+ Preserves sentence structure\n",
    "\n",
    "RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb54e700",
   "metadata": {},
   "source": [
    ">> ### ***üìö 3. Document Structure-Based Splitters***\n",
    "\n",
    "Leverages structured elements like headings, bullet points, or HTML tags for splitting ‚Äî common in PDFs, DOCX, or web pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaebe8e0",
   "metadata": {},
   "source": [
    "+ Useful for reports, articles, forms\n",
    "+ Keeps semantic sections intact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8478ba56",
   "metadata": {},
   "source": [
    "Examples:\n",
    "\n",
    "MarkdownHeaderTextSplitter (splits by #, ##, etc.)\n",
    "\n",
    "HTMLHeaderTextSplitter\n",
    "\n",
    "Language-aware splitters for code/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da38da73",
   "metadata": {},
   "source": [
    ">> ### ***üß† 4. Semantic Meaning-Based Splitters***\n",
    "\n",
    "Uses AI/embeddings to split text where meaning or context shifts, like paragraphs with different topics.\n",
    "\n",
    "+ Most intelligent and context-aware\n",
    "\n",
    "+ Preserves thought boundaries and meaning\n",
    "- Slower and computationally heavy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d5ee63",
   "metadata": {},
   "source": [
    "Examples:\n",
    "\n",
    "- SemanticChunker (uses embeddings)\n",
    "\n",
    "- SentenceTransformersTokenTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a9a80",
   "metadata": {},
   "source": [
    "| Type                     | Preserves Meaning | Fast?  | Use Case                                      |\n",
    "| ------------------------ | ----------------- | ------ | --------------------------------------------- |\n",
    "| Length-Based             | ‚ùå No              | ‚úÖ Yes  | Logs, uniform text                            |\n",
    "| Text Structure-Based     | ‚ö†Ô∏è Partial        | ‚úÖ Yes  | Articles, generic text                        |\n",
    "| Document Structure-Based | ‚úÖ Yes             | ‚ö†Ô∏è Mid | Structured documents like PDFs, blogs         |\n",
    "| Semantic Meaning-Based   | ‚úÖ‚úÖ Best           | ‚ùå No   | Topic-based summarization, advanced retrieval |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d558ac6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
